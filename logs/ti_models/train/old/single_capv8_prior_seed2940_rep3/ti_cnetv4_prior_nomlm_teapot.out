INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
wandb: Currently logged in as: tuk101234 (qlab-taewook). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.21
wandb: Run data is saved locally in /home/twkim/project/rich_context/textual_inversion/wandb/run-20240902_070719-kveznyck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-snowflake-462
wandb: ‚≠êÔ∏è View project at https://wandb.ai/qlab-taewook/TI%20MLM%20SINGLE
wandb: üöÄ View run at https://wandb.ai/qlab-taewook/TI%20MLM%20SINGLE/runs/kveznyck
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'timestep_spacing', 'sample_max_value', 'thresholding', 'dynamic_thresholding_ratio', 'variance_type', 'clip_sample_range', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'resnet_skip_time_act', 'dual_cross_attention', 'time_embedding_type', 'mid_block_type', 'addition_embed_type_num_heads', 'cross_attention_norm', 'encoder_hid_dim', 'only_cross_attention', 'time_embedding_act_fn', 'class_embeddings_concat', 'time_embedding_dim', 'use_linear_projection', 'projection_class_embeddings_input_dim', 'transformer_layers_per_block', 'time_cond_proj_dim', 'conv_in_kernel', 'resnet_out_scale_factor', 'class_embed_type', 'encoder_hid_dim_type', 'upcast_attention', 'conv_out_kernel', 'mid_block_only_cross_attention', 'timestep_post_act', 'addition_embed_type', 'resnet_time_scale_shift', 'num_class_embeds', 'num_attention_heads', 'addition_time_embed_dim'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 4
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 3001
set seed 2940
saved_models/ti_models/single_capv8_prior_seed2940_rep3/teapot/ti_cnetv4_prior_nomlm_teapot/src/command.txt command_path
ti_train.py item
--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 item
--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/teapot item
--learnable_property=object item
--placeholder_token1=<teapot> item
--train_prior_concept1=teapot item
--eval_prior_concept1=teapot item
--resolution=512 item
--train_batch_size=1 item
--gradient_accumulation_steps=4 item
--max_train_steps=3001 item
--learning_rate=5e-4 item
--lr_scheduler=constant item
--normalize_mask_embeds=0 item
--lr_warmup_steps=0 item
--output_dir=saved_models/ti_models/single_capv8_prior_seed2940_rep3/teapot item
--seed=2940 item
--mask_tokens=[MASK] item
--lambda_mlm=0 item
--freeze_mask_embedding=1 item
--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt item
--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt item
--mask_prob=0.15 item
--mlm_target=masked item
--mlm_batch_size=25 item
--scale_lr item
--eval_prompt_type=nonliving item
--train_prompt_type=nonliving item
--silent=0 item
--rev=0 item
--normalize_target1=0 item
--caption_root=../datasets_pkgs/captions/v8 item
--run_name=ti_cnetv4_prior_nomlm_teapot item
--report_to=wandb item
--project_name=TI MLM SINGLE item
--include_prior_concept=1 item
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
text_model.embeddings.token_embedding.weight text_encoder requires
None mask_token_ids
seeded
captions_nonliving_attr	13930
captions_nonliving_relations	22776
captions_nonliving_styles	1183
captions_nonliving_human_interactions	18792
captions_nonliving_backgrounds_subject	95918
seeded
captions_nonliving_attr	13930
captions_nonliving_relations	22776
captions_nonliving_styles	1183
captions_nonliving_human_interactions	18792
captions_nonliving_backgrounds_subject	95918
Steps:   0% 0/3001 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
INFO:__main__:STEP 0 Running validation... 
 Generating 8 images with prompt: ['a <teapot> teapot in the jungle', 'a <teapot> teapot with a city in the background', 'a <teapot> teapot with a mountain in the background', 'a <teapot> teapot with the Eiffel Tower in the background', 'a <teapot> teapot floating on top of water', 'a <teapot> teapot floating in an ocean of milk', 'a <teapot> teapot on top of the sidewalk in a crowded street', 'a cube shaped <teapot> teapot'].

  0% 0/25 [00:00<?, ?it/s][A
  4% 1/25 [00:00<00:09,  2.59it/s][A
  8% 2/25 [00:00<00:08,  2.78it/s][A
 12% 3/25 [00:01<00:07,  2.85it/s][A
 16% 4/25 [00:01<00:07,  2.86it/s][A
 20% 5/25 [00:01<00:06,  2.88it/s][A
 24% 6/25 [00:02<00:06,  2.90it/s][A
 28% 7/25 [00:02<00:06,  2.90it/s][A
 32% 8/25 [00:02<00:05,  2.91it/s][A
 36% 9/25 [00:03<00:05,  2.92it/s][A
 40% 10/25 [00:03<00:05,  2.91it/s][A
 44% 11/25 [00:03<00:04,  2.92it/s][A
 48% 12/25 [00:04<00:04,  2.93it/s][A
 52% 13/25 [00:04<00:04,  2.93it/s][A
 56% 14/25 [00:04<00:03,  2.93it/s][A
 60% 15/25 [00:05<00:03,  2.93it/s][A
 64% 16/25 [00:05<00:03,  2.92it/s][A
 68% 17/25 [00:05<00:02,  2.93it/s][A
 72% 18/25 [00:06<00:02,  2.93it/s][A
 76% 19/25 [00:06<00:02,  2.92it/s][A
 80% 20/25 [00:06<00:01,  2.92it/s][A
 84% 21/25 [00:07<00:01,  2.92it/s][A
 88% 22/25 [00:07<00:01,  2.92it/s][A
 92% 23/25 [00:07<00:00,  2.92it/s][A
 96% 24/25 [00:08<00:00,  2.92it/s][A
100% 25/25 [00:08<00:00,  2.91it/s][A100% 25/25 [00:09<00:00,  2.64it/s]
Steps:   0% 0/3001 [00:18<?, ?it/s, _runtime=28, _timestamp=1.73e+9, loss=0.179, lr=0.002, norm_target=8.42]Steps:   0% 1/3001 [00:18<15:08:07, 18.16s/it, _runtime=28, _timestamp=1.73e+9, loss=0.179, lr=0.002, norm_target=8.42]Steps:   0% 1/3001 [00:19<15:08:07, 18.16s/it, _runtime=29, _timestamp=1.73e+9, loss=0.548, lr=0.002, norm_target=8.42]Steps:   0% 2/3001 [00:19<6:44:39,  8.10s/it, _runtime=29, _timestamp=1.73e+9, loss=0.548, lr=0.002, norm_target=8.42] Steps:   0% 2/3001 [00:20<6:44:39,  8.10s/it, _runtime=30, _timestamp=1.73e+9, loss=0.103, lr=0.002, norm_target=8.42]Steps:   0% 3/3001 [00:20<4:02:24,  4.85s/it, _runtime=30, _timestamp=1.73e+9, loss=0.103, lr=0.002, norm_target=8.42]Steps:   0% 3/3001 [00:21<4:02:24,  4.85s/it, _runtime=31, _timestamp=1.73e+9, loss=0.00431, lr=0.002, norm_target=8.58]Steps:   0% 4/3001 [00:21<2:46:28,  3.33s/it, _runtime=31, _timestamp=1.73e+9, loss=0.00431, lr=0.002, norm_target=8.58]Steps:   0% 4/3001 [00:22<2:46:28,  3.33s/it, _runtime=32, _timestamp=1.73e+9, loss=0.00343, lr=0.002, norm_target=8.58]Steps:   0% 5/3001 [00:22<2:04:13,  2.49s/it, _runtime=32, _timestamp=1.73e+9, loss=0.00343, lr=0.002, norm_target=8.58]Steps:   0% 5/3001 [00:23<2:04:13,  2.49s/it, _runtime=33, _timestamp=1.73e+9, loss=0.0047, lr=0.002, norm_target=8.58] Steps:   0% 6/3001 [00:23<1:38:40,  1.98s/it, _runtime=33, _timestamp=1.73e+9, loss=0.0047, lr=0.002, norm_target=8.58]Steps:   0% 6/3001 [00:24<1:38:40,  1.98s/it, _runtime=34, _timestamp=1.73e+9, loss=0.0245, lr=0.002, norm_target=8.58]Steps:   0% 7/3001 [00:24<1:22:43,  1.66s/it, _runtime=34, _timestamp=1.73e+9, loss=0.0245, lr=0.002, norm_target=8.58]Steps:   0% 7/3001 [00:25<1:22:43,  1.66s/it, _runtime=35, _timestamp=1.73e+9, loss=0.143, lr=0.002, norm_target=8.71] Steps:   0% 8/3001 [00:25<1:12:15,  1.45s/it, _runtime=35, _timestamp=1.73e+9, loss=0.143, lr=0.002, norm_target=8.71]Steps:   0% 8/3001 [00:26<1:12:15,  1.45s/it, _runtime=36, _timestamp=1.73e+9, loss=0.268, lr=0.002, norm_target=8.71]Steps:   0% 9/3001 [00:26<1:05:15,  1.31s/it, _runtime=36, _timestamp=1.73e+9, loss=0.268, lr=0.002, norm_target=8.71]Steps:   0% 9/3001 [00:27<1:05:15,  1.31s/it, _runtime=37, _timestamp=1.73e+9, loss=0.181, lr=0.002, norm_target=8.71]Steps:   0% 10/3001 [00:27<1:00:25,  1.21s/it, _runtime=37, _timestamp=1.73e+9, loss=0.181, lr=0.002, norm_target=8.71]Steps:   0% 10/3001 [00:28<1:00:25,  1.21s/it, _runtime=38, _timestamp=1.73e+9, loss=0.0186, lr=0.002, norm_target=8.71]Steps:   0% 11/3001 [00:28<57:11,  1.15s/it, _runtime=38, _timestamp=1.73e+9, loss=0.0186, lr=0.002, norm_target=8.71]  Steps:   0% 11/3001 [00:29<57:11,  1.15s/it, _runtime=39, _timestamp=1.73e+9, loss=0.331, lr=0.002, norm_target=8.84] Steps:   0% 12/3001 [00:29<55:06,  1.11s/it, _runtime=39, _timestamp=1.73e+9, loss=0.331, lr=0.002, norm_target=8.84]Steps:   0% 12/3001 [00:30<55:06,  1.11s/it, _runtime=40, _timestamp=1.73e+9, loss=0.0849, lr=0.002, norm_target=8.84]Steps:   0% 13/3001 [00:30<53:27,  1.07s/it, _runtime=40, _timestamp=1.73e+9, loss=0.0849, lr=0.002, norm_target=8.84]Steps:   0% 13/3001 [00:31<53:27,  1.07s/it, _runtime=41, _timestamp=1.73e+9, loss=0.0749, lr=0.002, norm_target=8.84]Steps:   0% 14/3001 [00:31<52:33,  1.06s/it, _runtime=41, _timestamp=1.73e+9, loss=0.0749, lr=0.002, norm_target=8.84]Steps:   0% 14/3001 [00:32<52:33,  1.06s/it, _runtime=42, _timestamp=1.73e+9, loss=0.0159, lr=0.002, norm_target=8.84]Steps:   0% 15/3001 [00:32<51:50,  1.04s/it, _runtime=42, _timestamp=1.73e+9, loss=0.0159, lr=0.002, norm_target=8.84]Steps:   0% 15/3001 [00:33<51:50,  1.04s/it, _runtime=43, _timestamp=1.73e+9, loss=0.012, lr=0.002, norm_target=8.98] Steps:   1% 16/3001 [00:33<51:10,  1.03s/it, _runtime=43, _timestamp=1.73e+9, loss=0.012, lr=0.002, norm_target=8.98]Steps:   1% 16/3001 [00:34<51:10,  1.03s/it, _runtime=44, _timestamp=1.73e+9, loss=0.0155, lr=0.002, norm_target=8.98]Steps:   1% 17/3001 [00:34<50:45,  1.02s/it, _runtime=44, _timestamp=1.73e+9, loss=0.0155, lr=0.002, norm_target=8.98]Steps:   1% 17/3001 [00:35<50:45,  1.02s/it, _runtime=45, _timestamp=1.73e+9, loss=0.246, lr=0.002, norm_target=8.98] Steps:   1% 18/3001 [00:35<50:24,  1.01s/it, _runtime=45, _timestamp=1.73e+9, loss=0.246, lr=0.002, norm_target=8.98]Steps:   1% 18/3001 [00:36<50:24,  1.01s/it, _runtime=46, _timestamp=1.73e+9, loss=0.0188, lr=0.002, norm_target=8.98]Steps:   1% 19/3001 [00:36<50:07,  1.01s/it, _runtime=46, _timestamp=1.73e+9, loss=0.0188, lr=0.002, norm_target=8.98]Steps:   1% 19/3001 [00:37<50:07,  1.01s/it, _runtime=47, _timestamp=1.73e+9, loss=0.00235, lr=0.002, norm_target=9.15]Steps:   1% 20/3001 [00:37<54:10,  1.09s/it, _runtime=47, _timestamp=1.73e+9, loss=0.00235, lr=0.002, norm_target=9.15]Steps:   1% 20/3001 [00:38<54:10,  1.09s/it, _runtime=48, _timestamp=1.73e+9, loss=0.119, lr=0.002, norm_target=9.15]  Steps:   1% 21/3001 [00:38<52:51,  1.06s/it, _runtime=48, _timestamp=1.73e+9, loss=0.119, lr=0.002, norm_target=9.15]Steps:   1% 21/3001 [00:39<52:51,  1.06s/it, _runtime=49, _timestamp=1.73e+9, loss=0.237, lr=0.002, norm_target=9.15]Steps:   1% 22/3001 [00:39<52:05,  1.05s/it, _runtime=49, _timestamp=1.73e+9, loss=0.237, lr=0.002, norm_target=9.15]Steps:   1% 22/3001 [00:40<52:05,  1.05s/it, _runtime=50, _timestamp=1.73e+9, loss=0.0675, lr=0.002, norm_target=9.15]Steps:   1% 23/3001 [00:40<51:11,  1.03s/it, _runtime=50, _timestamp=1.73e+9, loss=0.0675, lr=0.002, norm_target=9.15]Steps:   1% 23/3001 [00:41<51:11,  1.03s/it, _runtime=51, _timestamp=1.73e+9, loss=0.101, lr=0.002, norm_target=9.33] Steps:   1% 24/3001 [00:41<50:58,  1.03s/it, _runtime=51, _timestamp=1.73e+9, loss=0.101, lr=0.002, norm_target=9.33]Steps:   1% 24/3001 [00:42<50:58,  1.03s/it, _runtime=52, _timestamp=1.73e+9, loss=0.143, lr=0.002, norm_target=9.33]Steps:   1% 25/3001 [00:42<50:33,  1.02s/it, _runtime=52, _timestamp=1.73e+9, loss=0.143, lr=0.002, norm_target=9.33]Steps:   1% 25/3001 [00:43<50:33,  1.02s/it, _runtime=53, _timestamp=1.73e+9, loss=0.0101, lr=0.002, norm_target=9.33]Steps:   1% 26/3001 [00:43<50:15,  1.01s/it, _runtime=53, _timestamp=1.73e+9, loss=0.0101, lr=0.002, norm_target=9.33]Steps:   1% 26/3001 [00:44<50:15,  1.01s/it, _runtime=54, _timestamp=1.73e+9, loss=0.0147, lr=0.002, norm_target=9.33]Steps:   1% 27/3001 [00:44<50:02,  1.01s/it, _runtime=54, _timestamp=1.73e+9, loss=0.0147, lr=0.002, norm_target=9.33]Steps:   1% 27/3001 [00:45<50:02,  1.01s/it, _runtime=55, _timestamp=1.73e+9, loss=0.0203, lr=0.002, norm_target=9.48]Steps:   1% 28/3001 [00:45<49:59,  1.01s/it, _runtime=55, _timestamp=1.73e+9, loss=0.0203, lr=0.002, norm_target=9.48]Steps:   1% 28/3001 [00:46<49:59,  1.01s/it, _runtime=56, _timestamp=1.73e+9, loss=0.177, lr=0.002, norm_target=9.48] Steps:   1% 29/3001 [00:46<50:06,  1.01s/it, _runtime=56, _timestamp=1.73e+9, loss=0.177, lr=0.002, norm_target=9.48]Steps:   1% 29/3001 [00:47<50:06,  1.01s/it, _runtime=57, _timestamp=1.73e+9, loss=0.0788, lr=0.002, norm_target=9.48]Steps:   1% 30/3001 [00:47<49:55,  1.01s/it, _runtime=57, _timestamp=1.73e+9, loss=0.0788, lr=0.002, norm_target=9.48]Steps:   1% 30/3001 [00:48<49:55,  1.01s/it, _runtime=58, _timestamp=1.73e+9, loss=0.214, lr=0.002, norm_target=9.48] Steps:   1% 31/3001 [00:48<49:51,  1.01s/it, _runtime=58, _timestamp=1.73e+9, loss=0.214, lr=0.002, norm_target=9.48]Steps:   1% 31/3001 [00:49<49:51,  1.01s/it, _runtime=59, _timestamp=1.73e+9, loss=0.201, lr=0.002, norm_target=9.63]Steps:   1% 32/3001 [00:49<49:45,  1.01s/it, _runtime=59, _timestamp=1.73e+9, loss=0.201, lr=0.002, norm_target=9.63]Steps:   1% 32/3001 [00:50<49:45,  1.01s/it, _runtime=60, _timestamp=1.73e+9, loss=0.203, lr=0.002, norm_target=9.63]Steps:   1% 33/3001 [00:50<49:54,  1.01s/it, _runtime=60, _timestamp=1.73e+9, loss=0.203, lr=0.002, norm_target=9.63]Steps:   1% 33/3001 [00:51<49:54,  1.01s/it, _runtime=61, _timestamp=1.73e+9, loss=0.0661, lr=0.002, norm_target=9.63]Steps:   1% 34/3001 [00:51<49:50,  1.01s/it, _runtime=61, _timestamp=1.73e+9, loss=0.0661, lr=0.002, norm_target=9.63]Steps:   1% 34/3001 [00:52<49:50,  1.01s/it, _runtime=62, _timestamp=1.73e+9, loss=0.0485, lr=0.002, norm_target=9.63]Steps:   1% 35/3001 [00:52<49:36,  1.00s/it, _runtime=62, _timestamp=1.73e+9, loss=0.0485, lr=0.002, norm_target=9.63]Steps:   1% 35/3001 [00:53<49:36,  1.00s/it, _runtime=63, _timestamp=1.73e+9, loss=0.0557, lr=0.002, norm_target=9.76]Steps:   1% 36/3001 [00:53<49:31,  1.00s/it, _runtime=63, _timestamp=1.73e+9, loss=0.0557, lr=0.002, norm_target=9.76]Steps:   1% 36/3001 [00:54<49:31,  1.00s/it, _runtime=64, _timestamp=1.73e+9, loss=0.0109, lr=0.002, norm_target=9.76]Steps:   1% 37/3001 [00:54<49:52,  1.01s/it, _runtime=64, _timestamp=1.73e+9, loss=0.0109, lr=0.002, norm_target=9.76]Steps:   1% 37/3001 [00:55<49:52,  1.01s/it, _runtime=65, _timestamp=1.73e+9, loss=0.049, lr=0.002, norm_target=9.76] Steps:   1% 38/3001 [00:55<49:45,  1.01s/it, _runtime=65, _timestamp=1.73e+9, loss=0.049, lr=0.002, norm_target=9.76]Steps:   1% 38/3001 [00:56<49:45,  1.01s/it, _runtime=66, _timestamp=1.73e+9, loss=0.0204, lr=0.002, norm_target=9.76]Steps:   1% 39/3001 [00:56<49:37,  1.01s/it, _runtime=66, _timestamp=1.73e+9, loss=0.0204, lr=0.002, norm_target=9.76]Steps:   1% 39/3001 [00:57<49:37,  1.01s/it, _runtime=67, _timestamp=1.73e+9, loss=0.0306, lr=0.002, norm_target=9.89]Steps:   1% 40/3001 [00:57<49:33,  1.00s/it, _runtime=67, _timestamp=1.73e+9, loss=0.0306, lr=0.002, norm_target=9.89]Steps:   1% 40/3001 [00:58<49:33,  1.00s/it, _runtime=68, _timestamp=1.73e+9, loss=0.0061, lr=0.002, norm_target=9.89]Steps:   1% 41/3001 [00:58<49:20,  1.00s/it, _runtime=68, _timestamp=1.73e+9, loss=0.0061, lr=0.002, norm_target=9.89]Steps:   1% 41/3001 [00:59<49:20,  1.00s/it, _runtime=69, _timestamp=1.73e+9, loss=0.0725, lr=0.002, norm_target=9.89]Steps:   1% 42/3001 [00:59<49:15,  1.00it/s, _runtime=69, _timestamp=1.73e+9, loss=0.0725, lr=0.002, norm_target=9.89]Steps:   1% 42/3001 [01:00<49:15,  1.00it/s, _runtime=70, _timestamp=1.73e+9, loss=0.334, lr=0.002, norm_target=9.89] Steps:   1% 43/3001 [01:00<49:21,  1.00s/it, _runtime=70, _timestamp=1.73e+9, loss=0.334, lr=0.002, norm_target=9.89]Steps:   1% 43/3001 [01:01<49:21,  1.00s/it, _runtime=71, _timestamp=1.73e+9, loss=0.00402, lr=0.002, norm_target=10]Steps:   1% 44/3001 [01:01<49:21,  1.00s/it, _runtime=71, _timestamp=1.73e+9, loss=0.00402, lr=0.002, norm_target=10]Steps:   1% 44/3001 [01:02<49:21,  1.00s/it, _runtime=72, _timestamp=1.73e+9, loss=0.0154, lr=0.002, norm_target=10] Steps:   1% 45/3001 [01:02<49:21,  1.00s/it, _runtime=72, _timestamp=1.73e+9, loss=0.0154, lr=0.002, norm_target=10]Steps:   1% 45/3001 [01:03<49:21,  1.00s/it, _runtime=73, _timestamp=1.73e+9, loss=0.00448, lr=0.002, norm_target=10]Steps:   2% 46/3001 [01:03<49:20,  1.00s/it, _runtime=73, _timestamp=1.73e+9, loss=0.00448, lr=0.002, norm_target=10]Steps:   2% 46/3001 [01:04<49:20,  1.00s/it, _runtime=74, _timestamp=1.73e+9, loss=0.00738, lr=0.002, norm_target=10]Steps:   2% 47/3001 [01:04<49:14,  1.00s/it, _runtime=74, _timestamp=1.73e+9, loss=0.00738, lr=0.002, norm_target=10]Steps:   2% 47/3001 [01:05<49:14,  1.00s/it, _runtime=75, _timestamp=1.73e+9, loss=0.458, lr=0.002, norm_target=10.2]Steps:   2% 48/3001 [01:05<49:09,  1.00it/s, _runtime=75, _timestamp=1.73e+9, loss=0.458, lr=0.002, norm_target=10.2]Steps:   2% 48/3001 [01:06<49:09,  1.00it/s, _runtime=76, _timestamp=1.73e+9, loss=0.00227, lr=0.002, norm_target=10.2]Steps:   2% 49/3001 [01:06<49:07,  1.00it/s, _runtime=76, _timestamp=1.73e+9, loss=0.00227, lr=0.002, norm_target=10.2]Steps:   2% 49/3001 [01:07<49:07,  1.00it/s, _runtime=77, _timestamp=1.73e+9, loss=0.00379, lr=0.002, norm_target=10.2]Steps:   2% 50/3001 [01:07<49:17,  1.00s/it, _runtime=77, _timestamp=1.73e+9, loss=0.00379, lr=0.002, norm_target=10.2]Steps:   2% 50/3001 [01:08<49:17,  1.00s/it, _runtime=78, _timestamp=1.73e+9, loss=0.00946, lr=0.002, norm_target=10.2]Steps:   2% 51/3001 [01:08<49:09,  1.00it/s, _runtime=78, _timestamp=1.73e+9, loss=0.00946, lr=0.002, norm_target=10.2]Steps:   2% 51/3001 [01:09<49:09,  1.00it/s, _runtime=79, _timestamp=1.73e+9, loss=0.459, lr=0.002, norm_target=10.3]  Steps:   2% 52/3001 [01:09<49:04,  1.00it/s, _runtime=79, _timestamp=1.73e+9, loss=0.459, lr=0.002, norm_target=10.3]Steps:   2% 52/3001 [01:10<49:04,  1.00it/s, _runtime=80, _timestamp=1.73e+9, loss=0.00192, lr=0.002, norm_target=10.3]Steps:   2% 53/3001 [01:10<49:03,  1.00it/s, _runtime=80, _timestamp=1.73e+9, loss=0.00192, lr=0.002, norm_target=10.3]Steps:   2% 53/3001 [01:11<49:03,  1.00it/s, _runtime=81, _timestamp=1.73e+9, loss=0.00464, lr=0.002, norm_target=10.3]Steps:   2% 54/3001 [01:11<49:03,  1.00it/s, _runtime=81, _timestamp=1.73e+9, loss=0.00464, lr=0.002, norm_target=10.3]Steps:   2% 54/3001 [01:12<49:03,  1.00it/s, _runtime=82, _timestamp=1.73e+9, loss=0.0526, lr=0.002, norm_target=10.3] Steps:   2% 55/3001 [01:12<48:58,  1.00it/s, _runtime=82, _timestamp=1.73e+9, loss=0.0526, lr=0.002, norm_target=10.3]Steps:   2% 55/3001 [01:13<48:58,  1.00it/s, _runtime=83, _timestamp=1.73e+9, loss=0.339, lr=0.002, norm_target=10.4] Steps:   2% 56/3001 [01:13<48:57,  1.00it/s, _runtime=83, _timestamp=1.73e+9, loss=0.339, lr=0.002, norm_target=10.4]Steps:   2% 56/3001 [01:14<48:57,  1.00it/s, _runtime=84, _timestamp=1.73e+9, loss=0.368, lr=0.002, norm_target=10.4]Steps:   2% 57/3001 [01:14<48:51,  1.00it/s, _runtime=84, _timestamp=1.73e+9, loss=0.368, lr=0.002, norm_target=10.4]Steps:   2% 57/3001 [01:15<48:51,  1.00it/s, _runtime=85, _timestamp=1.73e+9, loss=0.123, lr=0.002, norm_target=10.4]Steps:   2% 58/3001 [01:15<48:51,  1.00it/s, _runtime=85, _timestamp=1.73e+9, loss=0.123, lr=0.002, norm_target=10.4]Steps:   2% 58/3001 [01:16<48:51,  1.00it/s, _runtime=86, _timestamp=1.73e+9, loss=0.0716, lr=0.002, norm_target=10.4]Steps:   2% 59/3001 [01:16<48:47,  1.00it/s, _runtime=86, _timestamp=1.73e+9, loss=0.0716, lr=0.002, norm_target=10.4]Steps:   2% 59/3001 [01:17<48:47,  1.00it/s, _runtime=87, _timestamp=1.73e+9, loss=0.0182, lr=0.002, norm_target=10.6]Steps:   2% 60/3001 [01:17<48:47,  1.00it/s, _runtime=87, _timestamp=1.73e+9, loss=0.0182, lr=0.002, norm_target=10.6]Steps:   2% 60/3001 [01:18<48:47,  1.00it/s, _runtime=88, _timestamp=1.73e+9, loss=0.0149, lr=0.002, norm_target=10.6]Steps:   2% 61/3001 [01:18<48:51,  1.00it/s, _runtime=88, _timestamp=1.73e+9, loss=0.0149, lr=0.002, norm_target=10.6]Steps:   2% 61/3001 [01:19<48:51,  1.00it/s, _runtime=89, _timestamp=1.73e+9, loss=0.306, lr=0.002, norm_target=10.6] Steps:   2% 62/3001 [01:19<52:55,  1.08s/it, _runtime=89, _timestamp=1.73e+9, loss=0.306, lr=0.002, norm_target=10.6]Steps:   2% 62/3001 [01:20<52:55,  1.08s/it, _runtime=90, _timestamp=1.73e+9, loss=0.0392, lr=0.002, norm_target=10.6]Steps:   2% 63/3001 [01:20<51:40,  1.06s/it, _runtime=90, _timestamp=1.73e+9, loss=0.0392, lr=0.002, norm_target=10.6]Steps:   2% 63/3001 [01:21<51:40,  1.06s/it, _runtime=91, _timestamp=1.73e+9, loss=0.12, lr=0.002, norm_target=10.7]  Steps:   2% 64/3001 [01:21<50:45,  1.04s/it, _runtime=91, _timestamp=1.73e+9, loss=0.12, lr=0.002, norm_target=10.7]Steps:   2% 64/3001 [01:22<50:45,  1.04s/it, _runtime=92, _timestamp=1.73e+9, loss=0.0538, lr=0.002, norm_target=10.7]Steps:   2% 65/3001 [01:22<50:23,  1.03s/it, _runtime=92, _timestamp=1.73e+9, loss=0.0538, lr=0.002, norm_target=10.7]Steps:   2% 65/3001 [01:23<50:23,  1.03s/it, _runtime=93, _timestamp=1.73e+9, loss=0.00871, lr=0.002, norm_target=10.7]Steps:   2% 66/3001 [01:23<49:59,  1.02s/it, _runtime=93, _timestamp=1.73e+9, loss=0.00871, lr=0.002, norm_target=10.7]Steps:   2% 66/3001 [01:24<49:59,  1.02s/it, _runtime=94, _timestamp=1.73e+9, loss=0.0893, lr=0.002, norm_target=10.7] Steps:   2% 67/3001 [01:24<49:40,  1.02s/it, _runtime=94, _timestamp=1.73e+9, loss=0.0893, lr=0.002, norm_target=10.7]Steps:   2% 67/3001 [01:25<49:40,  1.02s/it, _runtime=95, _timestamp=1.73e+9, loss=0.0181, lr=0.002, norm_target=10.8]Steps:   2% 68/3001 [01:25<49:27,  1.01s/it, _runtime=95, _timestamp=1.73e+9, loss=0.0181, lr=0.002, norm_target=10.8]Steps:   2% 68/3001 [01:26<49:27,  1.01s/it, _runtime=96, _timestamp=1.73e+9, loss=0.0255, lr=0.002, norm_target=10.8]Steps:   2% 69/3001 [01:26<49:11,  1.01s/it, _runtime=96, _timestamp=1.73e+9, loss=0.0255, lr=0.002, norm_target=10.8]Steps:   2% 69/3001 [01:27<49:11,  1.01s/it, _runtime=97, _timestamp=1.73e+9, loss=0.114, lr=0.002, norm_target=10.8] Steps:   2% 70/3001 [01:27<49:08,  1.01s/it, _runtime=97, _timestamp=1.73e+9, loss=0.114, lr=0.002, norm_target=10.8]Steps:   2% 70/3001 [01:28<49:08,  1.01s/it, _runtime=98, _timestamp=1.73e+9, loss=0.0875, lr=0.002, norm_target=10.8]Steps:   2% 71/3001 [01:28<48:58,  1.00s/it, _runtime=98, _timestamp=1.73e+9, loss=0.0875, lr=0.002, norm_target=10.8]Steps:   2% 71/3001 [01:29<48:58,  1.00s/it, _runtime=99, _timestamp=1.73e+9, loss=0.178, lr=0.002, norm_target=11]   Steps:   2% 72/3001 [01:29<48:59,  1.00s/it, _runtime=99, _timestamp=1.73e+9, loss=0.178, lr=0.002, norm_target=11]Steps:   2% 72/3001 [01:30<48:59,  1.00s/it, _runtime=100, _timestamp=1.73e+9, loss=0.749, lr=0.002, norm_target=11]Steps:   2% 73/3001 [01:30<48:54,  1.00s/it, _runtime=100, _timestamp=1.73e+9, loss=0.749, lr=0.002, norm_target=11]Steps:   2% 73/3001 [01:31<48:54,  1.00s/it, _runtime=101, _timestamp=1.73e+9, loss=0.253, lr=0.002, norm_target=11]Steps:   2% 74/3001 [01:31<48:52,  1.00s/it, _runtime=101, _timestamp=1.73e+9, loss=0.253, lr=0.002, norm_target=11]Steps:   2% 74/3001 [01:32<48:52,  1.00s/it, _runtime=102, _timestamp=1.73e+9, loss=0.118, lr=0.002, norm_target=11]Steps:   2% 75/3001 [01:32<48:45,  1.00it/s, _runtime=102, _timestamp=1.73e+9, loss=0.118, lr=0.002, norm_target=11]Steps:   2% 75/3001 [01:33<48:45,  1.00it/s, _runtime=103, _timestamp=1.73e+9, loss=0.00546, lr=0.002, norm_target=11.1]Steps:   3% 76/3001 [01:33<48:45,  1.00s/it, _runtime=103, _timestamp=1.73e+9, loss=0.00546, lr=0.002, norm_target=11.1]Steps:   3% 76/3001 [01:34<48:45,  1.00s/it, _runtime=104, _timestamp=1.73e+9, loss=0.0551, lr=0.002, norm_target=11.1] Steps:   3% 77/3001 [01:34<48:42,  1.00it/s, _runtime=104, _timestamp=1.73e+9, loss=0.0551, lr=0.002, norm_target=11.1]Steps:   3% 77/3001 [01:35<48:42,  1.00it/s, _runtime=105, _timestamp=1.73e+9, loss=0.00637, lr=0.002, norm_target=11.1]Steps:   3% 78/3001 [01:35<48:35,  1.00it/s, _runtime=105, _timestamp=1.73e+9, loss=0.00637, lr=0.002, norm_target=11.1]Steps:   3% 78/3001 [01:36<48:35,  1.00it/s, _runtime=106, _timestamp=1.73e+9, loss=0.019, lr=0.002, norm_target=11.1]  Steps:   3% 79/3001 [01:36<48:26,  1.01it/s, _runtime=106, _timestamp=1.73e+9, loss=0.019, lr=0.002, norm_target=11.1]Steps:   3% 79/3001 [01:37<48:26,  1.01it/s, _runtime=107, _timestamp=1.73e+9, loss=0.137, lr=0.002, norm_target=11.2]Steps:   3% 80/3001 [01:37<48:26,  1.01it/s, _runtime=107, _timestamp=1.73e+9, loss=0.137, lr=0.002, norm_target=11.2]Steps:   3% 80/3001 [01:38<48:26,  1.01it/s, _runtime=108, _timestamp=1.73e+9, loss=0.0957, lr=0.002, norm_target=11.2]Steps:   3% 81/3001 [01:38<48:31,  1.00it/s, _runtime=108, _timestamp=1.73e+9, loss=0.0957, lr=0.002, norm_target=11.2]Steps:   3% 81/3001 [01:39<48:31,  1.00it/s, _runtime=109, _timestamp=1.73e+9, loss=0.00846, lr=0.002, norm_target=11.2]Steps:   3% 82/3001 [01:39<48:33,  1.00it/s, _runtime=109, _timestamp=1.73e+9, loss=0.00846, lr=0.002, norm_target=11.2]Steps:   3% 82/3001 [01:40<48:33,  1.00it/s, _runtime=110, _timestamp=1.73e+9, loss=0.0537, lr=0.002, norm_target=11.2] Steps:   3% 83/3001 [01:40<48:39,  1.00s/it, _runtime=110, _timestamp=1.73e+9, loss=0.0537, lr=0.002, norm_target=11.2]Steps:   3% 83/3001 [01:41<48:39,  1.00s/it, _runtime=111, _timestamp=1.73e+9, loss=0.397, lr=0.002, norm_target=11.3] Steps:   3% 84/3001 [01:41<48:33,  1.00it/s, _runtime=111, _timestamp=1.73e+9, loss=0.397, lr=0.002, norm_target=11.3]Steps:   3% 84/3001 [01:42<48:33,  1.00it/s, _runtime=112, _timestamp=1.73e+9, loss=0.0581, lr=0.002, norm_target=11.3]Steps:   3% 85/3001 [01:42<48:27,  1.00it/s, _runtime=112, _timestamp=1.73e+9, loss=0.0581, lr=0.002, norm_target=11.3]Steps:   3% 85/3001 [01:43<48:27,  1.00it/s, _runtime=113, _timestamp=1.73e+9, loss=0.369, lr=0.002, norm_target=11.3] Steps:   3% 86/3001 [01:43<48:36,  1.00s/it, _runtime=113, _timestamp=1.73e+9, loss=0.369, lr=0.002, norm_target=11.3]Steps:   3% 86/3001 [01:44<48:36,  1.00s/it, _runtime=114, _timestamp=1.73e+9, loss=0.00963, lr=0.002, norm_target=11.3]Steps:   3% 87/3001 [01:44<48:29,  1.00it/s, _runtime=114, _timestamp=1.73e+9, loss=0.00963, lr=0.002, norm_target=11.3]Steps:   3% 87/3001 [01:45<48:29,  1.00it/s, _runtime=115, _timestamp=1.73e+9, loss=0.0305, lr=0.002, norm_target=11.4] Steps:   3% 88/3001 [01:45<48:25,  1.00it/s, _runtime=115, _timestamp=1.73e+9, loss=0.0305, lr=0.002, norm_target=11.4]Steps:   3% 88/3001 [01:46<48:25,  1.00it/s, _runtime=116, _timestamp=1.73e+9, loss=0.0106, lr=0.002, norm_target=11.4]Steps:   3% 89/3001 [01:46<48:29,  1.00it/s, _runtime=116, _timestamp=1.73e+9, loss=0.0106, lr=0.002, norm_target=11.4]Steps:   3% 89/3001 [01:47<48:29,  1.00it/s, _runtime=117, _timestamp=1.73e+9, loss=0.0243, lr=0.002, norm_target=11.4]Steps:   3% 90/3001 [01:47<48:26,  1.00it/s, _runtime=117, _timestamp=1.73e+9, loss=0.0243, lr=0.002, norm_target=11.4]Steps:   3% 90/3001 [01:48<48:26,  1.00it/s, _runtime=118, _timestamp=1.73e+9, loss=0.123, lr=0.002, norm_target=11.4] Steps:   3% 91/3001 [01:48<48:23,  1.00it/s, _runtime=118, _timestamp=1.73e+9, loss=0.123, lr=0.002, norm_target=11.4]Steps:   3% 91/3001 [01:49<48:23,  1.00it/s, _runtime=119, _timestamp=1.73e+9, loss=0.0148, lr=0.002, norm_target=11.5]Steps:   3% 92/3001 [01:49<48:20,  1.00it/s, _runtime=119, _timestamp=1.73e+9, loss=0.0148, lr=0.002, norm_target=11.5]Steps:   3% 92/3001 [01:50<48:20,  1.00it/s, _runtime=120, _timestamp=1.73e+9, loss=0.03, lr=0.002, norm_target=11.5]  Steps:   3% 93/3001 [01:50<48:22,  1.00it/s, _runtime=120, _timestamp=1.73e+9, loss=0.03, lr=0.002, norm_target=11.5]Steps:   3% 93/3001 [01:51<48:22,  1.00it/s, _runtime=121, _timestamp=1.73e+9, loss=0.0101, lr=0.002, norm_target=11.5]Steps:   3% 94/3001 [01:51<48:21,  1.00it/s, _runtime=121, _timestamp=1.73e+9, loss=0.0101, lr=0.002, norm_target=11.5]Steps:   3% 94/3001 [01:52<48:21,  1.00it/s, _runtime=122, _timestamp=1.73e+9, loss=0.0311, lr=0.002, norm_target=11.5]Steps:   3% 95/3001 [01:52<48:19,  1.00it/s, _runtime=122, _timestamp=1.73e+9, loss=0.0311, lr=0.002, norm_target=11.5]Steps:   3% 95/3001 [01:53<48:19,  1.00it/s, _runtime=123, _timestamp=1.73e+9, loss=0.116, lr=0.002, norm_target=11.7] Steps:   3% 96/3001 [01:53<48:17,  1.00it/s, _runtime=123, _timestamp=1.73e+9, loss=0.116, lr=0.002, norm_target=11.7]Steps:   3% 96/3001 [01:54<48:17,  1.00it/s, _runtime=124, _timestamp=1.73e+9, loss=0.201, lr=0.002, norm_target=11.7]Steps:   3% 97/3001 [01:54<48:18,  1.00it/s, _runtime=124, _timestamp=1.73e+9, loss=0.201, lr=0.002, norm_target=11.7]Steps:   3% 97/3001 [01:55<48:18,  1.00it/s, _runtime=125, _timestamp=1.73e+9, loss=0.00838, lr=0.002, norm_target=11.7]Steps:   3% 98/3001 [01:55<48:16,  1.00it/s, _runtime=125, _timestamp=1.73e+9, loss=0.00838, lr=0.002, norm_target=11.7]Steps:   3% 98/3001 [01:56<48:16,  1.00it/s, _runtime=126, _timestamp=1.73e+9, loss=0.00737, lr=0.002, norm_target=11.7]Steps:   3% 99/3001 [01:56<48:16,  1.00it/s, _runtime=126, _timestamp=1.73e+9, loss=0.00737, lr=0.002, norm_target=11.7]Steps:   3% 99/3001 [01:58<48:16,  1.00it/s, _runtime=127, _timestamp=1.73e+9, loss=0.0916, lr=0.002, norm_target=11.8] Steps:   3% 100/3001 [01:58<52:07,  1.08s/it, _runtime=127, _timestamp=1.73e+9, loss=0.0916, lr=0.002, norm_target=11.8]INFO:__main__:STEP 100 Running validation... 
 Generating 8 images with prompt: ['a <teapot> teapot in the jungle', 'a <teapot> teapot with a city in the background', 'a <teapot> teapot with a mountain in the background', 'a <teapot> teapot with the Eiffel Tower in the background', 'a <teapot> teapot floating on top of water', 'a <teapot> teapot floating in an ocean of milk', 'a <teapot> teapot on top of the sidewalk in a crowded street', 'a cube shaped <teapot> teapot'].

  0% 0/25 [00:00<?, ?it/s][AGenerated

  4% 1/25 [00:00<00:08,  2.89it/s][A
  8% 2/25 [00:00<00:07,  2.89it/s][A
 12% 3/25 [00:01<00:07,  2.90it/s][A
 16% 4/25 [00:01<00:07,  2.89it/s][A
 20% 5/25 [00:01<00:06,  2.89it/s][A
 24% 6/25 [00:02<00:06,  2.89it/s][A
 28% 7/25 [00:02<00:06,  2.89it/s][A
 32% 8/25 [00:02<00:05,  2.89it/s][A
 36% 9/25 [00:03<00:05,  2.89it/s][A
 40% 10/25 [00:03<00:05,  2.90it/s][A
 44% 11/25 [00:03<00:04,  2.90it/s][A
 48% 12/25 [00:04<00:04,  2.89it/s][A
 52% 13/25 [00:04<00:04,  2.89it/s][A
 56% 14/25 [00:04<00:03,  2.89it/s][A
 60% 15/25 [00:05<00:03,  2.89it/s][A
 64% 16/25 [00:05<00:03,  2.89it/s][A
 68% 17/25 [00:05<00:02,  2.89it/s][A
 72% 18/25 [00:06<00:02,  2.89it/s][A
 76% 19/25 [00:06<00:02,  2.89it/s][A
 80% 20/25 [00:06<00:01,  2.89it/s][A
 84% 21/25 [00:07<00:01,  2.88it/s][A
 88% 22/25 [00:07<00:01,  2.88it/s][A
 92% 23/25 [00:07<00:00,  2.88it/s][A
 96% 24/25 [00:08<00:00,  2.88it/s][A
100% 25/25 [00:08<00:00,  2.88it/s][A100% 25/25 [00:09<00:00,  2.63it/s]
Steps:   3% 100/3001 [02:12<52:07,  1.08s/it, _runtime=142, _timestamp=1.73e+9, loss=0.38, lr=0.002, norm_target=11.8]  Steps:   3% 101/3001 [02:12<4:11:50,  5.21s/it, _runtime=142, _timestamp=1.73e+9, loss=0.38, lr=0.002, norm_target=11.8]Steps:   3% 101/3001 [02:13<4:11:50,  5.21s/it, _runtime=143, _timestamp=1.73e+9, loss=0.00799, lr=0.002, norm_target=11.8]Steps:   3% 102/3001 [02:13<3:12:03,  3.98s/it, _runtime=143, _timestamp=1.73e+9, loss=0.00799, lr=0.002, norm_target=11.8]Steps:   3% 102/3001 [02:14<3:12:03,  3.98s/it, _runtime=144, _timestamp=1.73e+9, loss=0.031, lr=0.002, norm_target=11.8]  Steps:   3% 103/3001 [02:14<2:28:55,  3.08s/it, _runtime=144, _timestamp=1.73e+9, loss=0.031, lr=0.002, norm_target=11.8]Steps:   3% 103/3001 [02:15<2:28:55,  3.08s/it, _runtime=145, _timestamp=1.73e+9, loss=0.166, lr=0.002, norm_target=11.9]Steps:   3% 104/3001 [02:15<1:58:42,  2.46s/it, _runtime=145, _timestamp=1.73e+9, loss=0.166, lr=0.002, norm_target=11.9]Steps:   3% 104/3001 [02:16<1:58:42,  2.46s/it, _runtime=146, _timestamp=1.73e+9, loss=0.306, lr=0.002, norm_target=11.9]Steps:   3% 105/3001 [02:16<1:37:28,  2.02s/it, _runtime=146, _timestamp=1.73e+9, loss=0.306, lr=0.002, norm_target=11.9]Steps:   3% 105/3001 [02:17<1:37:28,  2.02s/it, _runtime=147, _timestamp=1.73e+9, loss=0.368, lr=0.002, norm_target=11.9]Steps:   4% 106/3001 [02:17<1:22:31,  1.71s/it, _runtime=147, _timestamp=1.73e+9, loss=0.368, lr=0.002, norm_target=11.9]Steps:   4% 106/3001 [02:18<1:22:31,  1.71s/it, _runtime=148, _timestamp=1.73e+9, loss=0.143, lr=0.002, norm_target=11.9]Steps:   4% 107/3001 [02:18<1:12:15,  1.50s/it, _runtime=148, _timestamp=1.73e+9, loss=0.143, lr=0.002, norm_target=11.9]Steps:   4% 107/3001 [02:19<1:12:15,  1.50s/it, _runtime=149, _timestamp=1.73e+9, loss=0.0134, lr=0.002, norm_target=11.9]Steps:   4% 108/3001 [02:19<1:05:01,  1.35s/it, _runtime=149, _timestamp=1.73e+9, loss=0.0134, lr=0.002, norm_target=11.9]Steps:   4% 108/3001 [02:20<1:05:01,  1.35s/it, _runtime=150, _timestamp=1.73e+9, loss=0.313, lr=0.002, norm_target=11.9] Steps:   4% 109/3001 [02:20<59:55,  1.24s/it, _runtime=150, _timestamp=1.73e+9, loss=0.313, lr=0.002, norm_target=11.9]  Steps:   4% 109/3001 [02:21<59:55,  1.24s/it, _runtime=151, _timestamp=1.73e+9, loss=0.116, lr=0.002, norm_target=11.9]Steps:   4% 110/3001 [02:21<56:17,  1.17s/it, _runtime=151, _timestamp=1.73e+9, loss=0.116, lr=0.002, norm_target=11.9]Steps:   4% 110/3001 [02:22<56:17,  1.17s/it, _runtime=152, _timestamp=1.73e+9, loss=0.0654, lr=0.002, norm_target=11.9]Steps:   4% 111/3001 [02:22<53:44,  1.12s/it, _runtime=152, _timestamp=1.73e+9, loss=0.0654, lr=0.002, norm_target=11.9]Steps:   4% 111/3001 [02:23<53:44,  1.12s/it, _runtime=153, _timestamp=1.73e+9, loss=0.0964, lr=0.002, norm_target=12]  Steps:   4% 112/3001 [02:23<52:04,  1.08s/it, _runtime=153, _timestamp=1.73e+9, loss=0.0964, lr=0.002, norm_target=12]Steps:   4% 112/3001 [02:24<52:04,  1.08s/it, _runtime=154, _timestamp=1.73e+9, loss=0.0728, lr=0.002, norm_target=12]Steps:   4% 113/3001 [02:24<50:46,  1.05s/it, _runtime=154, _timestamp=1.73e+9, loss=0.0728, lr=0.002, norm_target=12]Steps:   4% 113/3001 [02:25<50:46,  1.05s/it, _runtime=155, _timestamp=1.73e+9, loss=0.0221, lr=0.002, norm_target=12]Steps:   4% 114/3001 [02:25<49:53,  1.04s/it, _runtime=155, _timestamp=1.73e+9, loss=0.0221, lr=0.002, norm_target=12]Steps:   4% 114/3001 [02:26<49:53,  1.04s/it, _runtime=156, _timestamp=1.73e+9, loss=0.477, lr=0.002, norm_target=12] Steps:   4% 115/3001 [02:26<49:10,  1.02s/it, _runtime=156, _timestamp=1.73e+9, loss=0.477, lr=0.002, norm_target=12]Steps:   4% 115/3001 [02:27<49:10,  1.02s/it, _runtime=157, _timestamp=1.73e+9, loss=0.0722, lr=0.002, norm_target=12.1]Steps:   4% 116/3001 [02:27<48:49,  1.02s/it, _runtime=157, _timestamp=1.73e+9, loss=0.0722, lr=0.002, norm_target=12.1]Steps:   4% 116/3001 [02:28<48:49,  1.02s/it, _runtime=158, _timestamp=1.73e+9, loss=0.0469, lr=0.002, norm_target=12.1]Steps:   4% 117/3001 [02:28<48:30,  1.01s/it, _runtime=158, _timestamp=1.73e+9, loss=0.0469, lr=0.002, norm_target=12.1]Steps:   4% 117/3001 [02:29<48:30,  1.01s/it, _runtime=159, _timestamp=1.73e+9, loss=0.0349, lr=0.002, norm_target=12.1]Steps:   4% 118/3001 [02:29<48:19,  1.01s/it, _runtime=159, _timestamp=1.73e+9, loss=0.0349, lr=0.002, norm_target=12.1]Steps:   4% 118/3001 [02:30<48:19,  1.01s/it, _runtime=160, _timestamp=1.73e+9, loss=0.0889, lr=0.002, norm_target=12.1]Steps:   4% 119/3001 [02:30<48:08,  1.00s/it, _runtime=160, _timestamp=1.73e+9, loss=0.0889, lr=0.002, norm_target=12.1]Steps:   4% 119/3001 [02:31<48:08,  1.00s/it, _runtime=161, _timestamp=1.73e+9, loss=0.0448, lr=0.002, norm_target=12.2]Steps:   4% 120/3001 [02:31<48:07,  1.00s/it, _runtime=161, _timestamp=1.73e+9, loss=0.0448, lr=0.002, norm_target=12.2]Steps:   4% 120/3001 [02:32<48:07,  1.00s/it, _runtime=162, _timestamp=1.73e+9, loss=0.199, lr=0.002, norm_target=12.2] Steps:   4% 121/3001 [02:32<48:10,  1.00s/it, _runtime=162, _timestamp=1.73e+9, loss=0.199, lr=0.002, norm_target=12.2]Steps:   4% 121/3001 [02:33<48:10,  1.00s/it, _runtime=163, _timestamp=1.73e+9, loss=0.0224, lr=0.002, norm_target=12.2]Steps:   4% 122/3001 [02:33<48:04,  1.00s/it, _runtime=163, _timestamp=1.73e+9, loss=0.0224, lr=0.002, norm_target=12.2]Steps:   4% 122/3001 [02:34<48:04,  1.00s/it, _runtime=164, _timestamp=1.73e+9, loss=0.0567, lr=0.002, norm_target=12.2]Steps:   4% 123/3001 [02:34<48:04,  1.00s/it, _runtime=164, _timestamp=1.73e+9, loss=0.0567, lr=0.002, norm_target=12.2]Steps:   4% 123/3001 [02:35<48:04,  1.00s/it, _runtime=165, _timestamp=1.73e+9, loss=0.444, lr=0.002, norm_target=12.3] Steps:   4% 124/3001 [02:35<48:16,  1.01s/it, _runtime=165, _timestamp=1.73e+9, loss=0.444, lr=0.002, norm_target=12.3]Steps:   4% 124/3001 [02:36<48:16,  1.01s/it, _runtime=166, _timestamp=1.73e+9, loss=0.00367, lr=0.002, norm_target=12.3]Steps:   4% 125/3001 [02:36<48:11,  1.01s/it, _runtime=166, _timestamp=1.73e+9, loss=0.00367, lr=0.002, norm_target=12.3]Steps:   4% 125/3001 [02:37<48:11,  1.01s/it, _runtime=167, _timestamp=1.73e+9, loss=0.0296, lr=0.002, norm_target=12.3] Steps:   4% 126/3001 [02:37<48:03,  1.00s/it, _runtime=167, _timestamp=1.73e+9, loss=0.0296, lr=0.002, norm_target=12.3]Steps:   4% 126/3001 [02:38<48:03,  1.00s/it, _runtime=168, _timestamp=1.73e+9, loss=0.00907, lr=0.002, norm_target=12.3]Steps:   4% 127/3001 [02:38<48:19,  1.01s/it, _runtime=168, _timestamp=1.73e+9, loss=0.00907, lr=0.002, norm_target=12.3]Steps:   4% 127/3001 [02:39<48:19,  1.01s/it, _runtime=169, _timestamp=1.73e+9, loss=0.00776, lr=0.002, norm_target=12.4]Steps:   4% 128/3001 [02:39<48:11,  1.01s/it, _runtime=169, _timestamp=1.73e+9, loss=0.00776, lr=0.002, norm_target=12.4]Steps:   4% 128/3001 [02:40<48:11,  1.01s/it, _runtime=170, _timestamp=1.73e+9, loss=0.066, lr=0.002, norm_target=12.4]  Steps:   4% 129/3001 [02:40<48:03,  1.00s/it, _runtime=170, _timestamp=1.73e+9, loss=0.066, lr=0.002, norm_target=12.4]Steps:   4% 129/3001 [02:41<48:03,  1.00s/it, _runtime=171, _timestamp=1.73e+9, loss=0.324, lr=0.002, norm_target=12.4]Steps:   4% 130/3001 [02:41<47:59,  1.00s/it, _runtime=171, _timestamp=1.73e+9, loss=0.324, lr=0.002, norm_target=12.4]Steps:   4% 130/3001 [02:42<47:59,  1.00s/it, _runtime=172, _timestamp=1.73e+9, loss=0.0031, lr=0.002, norm_target=12.4]Steps:   4% 131/3001 [02:42<47:53,  1.00s/it, _runtime=172, _timestamp=1.73e+9, loss=0.0031, lr=0.002, norm_target=12.4]Steps:   4% 131/3001 [02:43<47:53,  1.00s/it, _runtime=173, _timestamp=1.73e+9, loss=0.0193, lr=0.002, norm_target=12.5]Steps:   4% 132/3001 [02:43<47:55,  1.00s/it, _runtime=173, _timestamp=1.73e+9, loss=0.0193, lr=0.002, norm_target=12.5]Steps:   4% 132/3001 [02:44<47:55,  1.00s/it, _runtime=174, _timestamp=1.73e+9, loss=0.0789, lr=0.002, norm_target=12.5]Steps:   4% 133/3001 [02:44<47:50,  1.00s/it, _runtime=174, _timestamp=1.73e+9, loss=0.0789, lr=0.002, norm_target=12.5]Steps:   4% 133/3001 [02:45<47:50,  1.00s/it, _runtime=175, _timestamp=1.73e+9, loss=0.942, lr=0.002, norm_target=12.5] Steps:   4% 134/3001 [02:45<47:49,  1.00s/it, _runtime=175, _timestamp=1.73e+9, loss=0.942, lr=0.002, norm_target=12.5]Steps:   4% 134/3001 [02:46<47:49,  1.00s/it, _runtime=176, _timestamp=1.73e+9, loss=0.00221, lr=0.002, norm_target=12.5]Steps:   4% 135/3001 [02:46<47:48,  1.00s/it, _runtime=176, _timestamp=1.73e+9, loss=0.00221, lr=0.002, norm_target=12.5]Steps:   4% 135/3001 [02:47<47:48,  1.00s/it, _runtime=177, _timestamp=1.73e+9, loss=0.0322, lr=0.002, norm_target=12.6] Steps:   5% 136/3001 [02:47<47:51,  1.00s/it, _runtime=177, _timestamp=1.73e+9, loss=0.0322, lr=0.002, norm_target=12.6]Steps:   5% 136/3001 [02:48<47:51,  1.00s/it, _runtime=178, _timestamp=1.73e+9, loss=0.0925, lr=0.002, norm_target=12.6]Steps:   5% 137/3001 [02:48<47:50,  1.00s/it, _runtime=178, _timestamp=1.73e+9, loss=0.0925, lr=0.002, norm_target=12.6]Steps:   5% 137/3001 [02:49<47:50,  1.00s/it, _runtime=179, _timestamp=1.73e+9, loss=0.097, lr=0.002, norm_target=12.6] Steps:   5% 138/3001 [02:49<47:50,  1.00s/it, _runtime=179, _timestamp=1.73e+9, loss=0.097, lr=0.002, norm_target=12.6]Steps:   5% 138/3001 [02:51<47:50,  1.00s/it, _runtime=180, _timestamp=1.73e+9, loss=0.0763, lr=0.002, norm_target=12.6]Steps:   5% 139/3001 [02:51<47:54,  1.00s/it, _runtime=180, _timestamp=1.73e+9, loss=0.0763, lr=0.002, norm_target=12.6]Steps:   5% 139/3001 [02:51<47:54,  1.00s/it, _runtime=181, _timestamp=1.73e+9, loss=0.00912, lr=0.002, norm_target=12.7]Steps:   5% 140/3001 [02:52<47:48,  1.00s/it, _runtime=181, _timestamp=1.73e+9, loss=0.00912, lr=0.002, norm_target=12.7]439510309 worker_seed
439510306 worker_seed
439510307 worker_seed
439510308 worker_seed
Generated
Traceback (most recent call last):
  File "/home/twkim/project/rich_context/textual_inversion/ti_train.py", line 985, in <module>
    main()
  File "/home/twkim/project/rich_context/textual_inversion/ti_train.py", line 819, in main
    caption_log_file=open(caption_log_path,'a')
FileNotFoundError: [Errno 2] No such file or directory: 'saved_models/ti_models/single_capv8_prior_seed2940_rep3/teapot/ti_cnetv4_prior_nomlm_teapot/src/log_captions.txt'
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 3.403 MB of 3.403 MB uploaded (0.000 MB deduped)wandb: \ 3.403 MB of 3.403 MB uploaded (0.000 MB deduped)wandb: | 3.403 MB of 3.403 MB uploaded (0.000 MB deduped)wandb: / 3.403 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: - 3.403 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: \ 3.403 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: | 3.414 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: / 3.426 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: - 3.426 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: \ 3.426 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: | 3.426 MB of 3.426 MB uploaded (0.000 MB deduped)wandb: / 3.426 MB of 3.426 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:        loss ‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: norm_target ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:        loss 0.00912
wandb:          lr 0.002
wandb: norm_target 12.66157
wandb: 
wandb: Synced generous-snowflake-462: https://wandb.ai/qlab-taewook/TI%20MLM%20SINGLE/runs/kveznyck
wandb: Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240902_070719-kveznyck/logs
Traceback (most recent call last):
  File "/home/twkim/anaconda3/envs/context/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1023, in launch_command
    simple_launcher(args)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/accelerate/commands/launch.py", line 643, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/twkim/anaconda3/envs/context/bin/python', 'ti_train.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/teapot', '--learnable_property=object', '--placeholder_token1=<teapot>', '--train_prior_concept1=teapot', '--eval_prior_concept1=teapot', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=4', '--max_train_steps=3001', '--learning_rate=5e-4', '--lr_scheduler=constant', '--normalize_mask_embeds=0', '--lr_warmup_steps=0', '--output_dir=saved_models/ti_models/single_capv8_prior_seed2940_rep3/teapot', '--seed=2940', '--mask_tokens=[MASK]', '--lambda_mlm=0', '--freeze_mask_embedding=1', '--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt', '--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt', '--mask_prob=0.15', '--mlm_target=masked', '--mlm_batch_size=25', '--scale_lr', '--eval_prompt_type=nonliving', '--train_prompt_type=nonliving', '--silent=0', '--rev=0', '--normalize_target1=0', '--caption_root=../datasets_pkgs/captions/v8', '--run_name=ti_cnetv4_prior_nomlm_teapot', '--report_to=wandb', '--project_name=TI MLM SINGLE', '--include_prior_concept=1']' returned non-zero exit status 1.
